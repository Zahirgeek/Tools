#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOv8 ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»è„šæœ¬
åŠŸèƒ½ï¼šå¯¹å›¾åƒå’Œè§†é¢‘è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶æ ¹æ®æ£€æµ‹ç»“æœè¿›è¡Œåˆ†ç±»ä¿å­˜
"""

import os
import argparse
import shutil
from pathlib import Path
import cv2
from ultralytics import YOLO
import numpy as np
from PIL import Image
import logging
from typing import List, Tuple, Dict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import threading
from queue import Queue
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class YOLODetectionClassifier:
    """YOLOæ£€æµ‹åˆ†ç±»å™¨"""
    
    def __init__(self, model_path: str, classes_path: str, confidence_threshold: float = 0.5):
        """
        åˆå§‹åŒ–æ£€æµ‹åˆ†ç±»å™¨
        
        Args:
            model_path: YOLOæ¨¡å‹è·¯å¾„
            classes_path: ç±»åˆ«æ–‡ä»¶è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.model_path = model_path
        self.classes_path = classes_path
        self.confidence_threshold = confidence_threshold
        
        # åŠ è½½æ¨¡å‹
        logger.info(f"æ­£åœ¨åŠ è½½YOLOæ¨¡å‹: {model_path}")
        self.model = YOLO(model_path)
        
        # åŠ è½½ç±»åˆ«
        self.classes = self._load_classes(classes_path)
        logger.info(f"åŠ è½½äº† {len(self.classes)} ä¸ªç±»åˆ«: {self.classes}")
        logger.info(f"ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®ä¸º: {self.confidence_threshold}")
    
    def _load_classes(self, classes_path: str) -> List[str]:
        """åŠ è½½ç±»åˆ«æ–‡ä»¶"""
        with open(classes_path, 'r', encoding='utf-8') as f:
            classes = [line.strip() for line in f.readlines() if line.strip()]
        return classes
    
    def detect_image(self, image_path: str, processor=None) -> Tuple[List[str], np.ndarray, dict, float]:
        """
        æ£€æµ‹å•å¼ å›¾åƒ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            processor: æ–‡ä»¶å¤„ç†å™¨ï¼ˆç”¨äºè®°å½•æ¨ç†æ—¶é—´ï¼‰
            
        Returns:
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«åˆ—è¡¨
            image: åŸå›¾åƒ
            results_info: æ£€æµ‹ç»“æœä¿¡æ¯
            inference_time: æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return [], None, {}, 0.0
        
        # è®°å½•æ¨ç†é˜¶æ®µå¼€å§‹æ—¶é—´
        if processor:
            processor.record_inference_start()
        
        # è¿›è¡Œæ£€æµ‹å¹¶è®¡æ—¶
        inference_start = time.time()
        results = self.model(image_path, conf=self.confidence_threshold)
        inference_time = time.time() - inference_start
        
        # è®°å½•æ¨ç†é˜¶æ®µç»“æŸæ—¶é—´
        if processor:
            processor.record_inference_end()
        
        detected_classes = []
        results_info = {
            'detections': [],
            'class_counts': {}
        }
        
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None and len(result.boxes) > 0:
                for box in result.boxes:
                    cls_id = int(box.cls.cpu().numpy()[0])
                    confidence = float(box.conf.cpu().numpy()[0])
                    
                    # ç¡®ä¿ç½®ä¿¡åº¦æ»¡è¶³é˜ˆå€¼è¦æ±‚
                    if cls_id < len(self.classes) and confidence >= self.confidence_threshold:
                        class_name = self.classes[cls_id]
                        if class_name not in detected_classes:
                            detected_classes.append(class_name)
                        
                        # è®°å½•æ£€æµ‹ä¿¡æ¯
                        bbox = box.xyxy.cpu().numpy()[0].tolist()
                        results_info['detections'].append({
                            'class': class_name,
                            'confidence': confidence,
                            'bbox': bbox
                        })
                        
                        # ç»Ÿè®¡ç±»åˆ«æ•°é‡
                        if class_name not in results_info['class_counts']:
                            results_info['class_counts'][class_name] = 0
                        results_info['class_counts'][class_name] += 1
                    elif cls_id < len(self.classes):
                        # è®°å½•è¢«è¿‡æ»¤æ‰çš„ä½ç½®ä¿¡åº¦æ£€æµ‹
                        class_name = self.classes[cls_id]
                        logger.debug(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f} < {self.confidence_threshold:.3f})")
        
        return detected_classes, image, results_info, inference_time
    
    def detect_images_batch(self, image_paths: List[str], batch_size: int = 8, processor=None) -> List[Tuple[str, List[str], np.ndarray, dict, float]]:
        """
        æ‰¹é‡æ£€æµ‹å¤šå¼ å›¾åƒ
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            processor: æ–‡ä»¶å¤„ç†å™¨ï¼ˆç”¨äºè®°å½•æ¨ç†æ—¶é—´ï¼‰
            
        Returns:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(image_path, detected_classes, image, results_info, inference_time)
        """
        all_results = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i + batch_size]
            
            # è¯»å–æ‰¹é‡å›¾åƒ
            batch_images = []
            valid_paths = []
            
            for path in batch_paths:
                image = cv2.imread(path)
                if image is not None:
                    batch_images.append(image)
                    valid_paths.append(path)
                else:
                    logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {path}")
                    all_results.append((path, [], None, {}, 0.0))
            
            if not batch_images:
                continue
            
            # è®°å½•æ¨ç†é˜¶æ®µå¼€å§‹æ—¶é—´
            if processor:
                processor.record_inference_start()
            
            # æ‰¹é‡æ¨ç†
            try:
                batch_inference_start = time.time()
                results = self.model(batch_images, conf=self.confidence_threshold)
                batch_inference_time = time.time() - batch_inference_start
                avg_inference_time = batch_inference_time / len(batch_images)
                
                # è®°å½•æ¨ç†é˜¶æ®µç»“æŸæ—¶é—´
                if processor:
                    processor.record_inference_end()
                
                # å¤„ç†æ¯ä¸ªç»“æœ
                for j, (path, image, result) in enumerate(zip(valid_paths, batch_images, results)):
                    detected_classes = []
                    results_info = {
                        'detections': [],
                        'class_counts': {}
                    }
                    
                    if result.boxes is not None and len(result.boxes) > 0:
                        for box in result.boxes:
                            cls_id = int(box.cls.cpu().numpy()[0])
                            confidence = float(box.conf.cpu().numpy()[0])
                            
                            # ç¡®ä¿ç½®ä¿¡åº¦æ»¡è¶³é˜ˆå€¼è¦æ±‚
                            if cls_id < len(self.classes) and confidence >= self.confidence_threshold:
                                class_name = self.classes[cls_id]
                                if class_name not in detected_classes:
                                    detected_classes.append(class_name)
                                
                                # è®°å½•æ£€æµ‹ä¿¡æ¯
                                bbox = box.xyxy.cpu().numpy()[0].tolist()
                                results_info['detections'].append({
                                    'class': class_name,
                                    'confidence': confidence,
                                    'bbox': bbox
                                })
                                
                                # ç»Ÿè®¡ç±»åˆ«æ•°é‡
                                if class_name not in results_info['class_counts']:
                                    results_info['class_counts'][class_name] = 0
                                results_info['class_counts'][class_name] += 1
                            elif cls_id < len(self.classes):
                                # è®°å½•è¢«è¿‡æ»¤æ‰çš„ä½ç½®ä¿¡åº¦æ£€æµ‹
                                class_name = self.classes[cls_id]
                                logger.debug(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f} < {self.confidence_threshold:.3f})")
                    
                    all_results.append((path, detected_classes, image, results_info, avg_inference_time))
                    
            except Exception as e:
                logger.error(f"æ‰¹é‡æ¨ç†å¤±è´¥: {e}")
                # å¤±è´¥æ—¶å›é€€åˆ°å•å¼ å¤„ç†
                for path in valid_paths:
                    try:
                        detected_classes, image, results_info, inference_time = self.detect_image(path, processor)
                        all_results.append((path, detected_classes, image, results_info, inference_time))
                    except Exception as e2:
                        logger.error(f"å•å¼ å›¾åƒå¤„ç†å¤±è´¥ {path}: {e2}")
                        all_results.append((path, [], None, {}, 0.0))
        
        return all_results
    
    def detect_video_frame(self, frame: np.ndarray, processor=None) -> Tuple[List[str], dict, float]:
        """
        æ£€æµ‹è§†é¢‘å¸§
        
        Args:
            frame: è§†é¢‘å¸§
            processor: æ–‡ä»¶å¤„ç†å™¨ï¼ˆç”¨äºè®°å½•æ¨ç†æ—¶é—´ï¼‰
            
        Returns:
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«åˆ—è¡¨
            results_info: æ£€æµ‹ç»“æœä¿¡æ¯
            inference_time: æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # è®°å½•æ¨ç†é˜¶æ®µå¼€å§‹æ—¶é—´
        if processor:
            processor.record_inference_start()
        
        inference_start = time.time()
        results = self.model(frame, conf=self.confidence_threshold)
        inference_time = time.time() - inference_start
        
        # è®°å½•æ¨ç†é˜¶æ®µç»“æŸæ—¶é—´
        if processor:
            processor.record_inference_end()
        
        detected_classes = []
        results_info = {
            'detections': [],
            'class_counts': {}
        }
        
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None and len(result.boxes) > 0:
                for box in result.boxes:
                    cls_id = int(box.cls.cpu().numpy()[0])
                    confidence = float(box.conf.cpu().numpy()[0])
                    
                    # ç¡®ä¿ç½®ä¿¡åº¦æ»¡è¶³é˜ˆå€¼è¦æ±‚
                    if cls_id < len(self.classes) and confidence >= self.confidence_threshold:
                        class_name = self.classes[cls_id]
                        if class_name not in detected_classes:
                            detected_classes.append(class_name)
                        
                        bbox = box.xyxy.cpu().numpy()[0].tolist()
                        results_info['detections'].append({
                            'class': class_name,
                            'confidence': confidence,
                            'bbox': bbox
                        })
                        
                        if class_name not in results_info['class_counts']:
                            results_info['class_counts'][class_name] = 0
                        results_info['class_counts'][class_name] += 1
                    elif cls_id < len(self.classes):
                        # è®°å½•è¢«è¿‡æ»¤æ‰çš„ä½ç½®ä¿¡åº¦æ£€æµ‹
                        class_name = self.classes[cls_id]
                        logger.debug(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f} < {self.confidence_threshold:.3f})")
        
        return detected_classes, results_info, inference_time
    
    def visualize_detection(self, image: np.ndarray, results_info: dict, target_class: str = None) -> np.ndarray:
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ
        
        Args:
            image: åŸå›¾åƒ
            results_info: æ£€æµ‹ç»“æœä¿¡æ¯
            target_class: ç›®æ ‡ç±»åˆ«ï¼Œå¦‚æœæŒ‡å®šåˆ™åªæ˜¾ç¤ºè¯¥ç±»åˆ«çš„æ£€æµ‹æ¡†
            
        Returns:
            visualized_image: å¯è§†åŒ–åçš„å›¾åƒ
        """
        vis_image = image.copy()
        height, width = vis_image.shape[:2]
        
        for detection in results_info['detections']:
            class_name = detection['class']
            confidence = detection['confidence']
            
            # å¦‚æœæŒ‡å®šäº†ç›®æ ‡ç±»åˆ«ï¼Œåˆ™åªæ˜¾ç¤ºè¯¥ç±»åˆ«çš„æ£€æµ‹æ¡†
            if target_class is not None and class_name != target_class:
                continue
            
            bbox = detection['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            
            # ç¡®ä¿è¾¹ç•Œæ¡†åæ ‡åœ¨å›¾ç‰‡èŒƒå›´å†…
            x1 = max(0, min(x1, width - 1))
            y1 = max(0, min(y1, height - 1))
            x2 = max(0, min(x2, width - 1))
            y2 = max(0, min(y2, height - 1))
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.5
            thickness = 2
            
            # è·å–æ–‡å­—å°ºå¯¸
            (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
            
            # è®¡ç®—æ ‡ç­¾èƒŒæ™¯æ¡†çš„ä½ç½®
            label_x = x1
            label_y = y1 - 10  # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹ç•™10åƒç´ é—´è·
            
            # å¦‚æœæ ‡ç­¾èƒŒæ™¯æ¡†è¶…å‡ºä¸Šè¾¹ç•Œï¼Œåˆ™æ”¾åœ¨è¾¹ç•Œæ¡†ä¸‹æ–¹
            if label_y - text_height - baseline < 0:
                label_y = y2 + text_height + baseline + 10
            
            # å¦‚æœæ ‡ç­¾èƒŒæ™¯æ¡†è¶…å‡ºä¸‹è¾¹ç•Œï¼Œåˆ™æ”¾åœ¨è¾¹ç•Œæ¡†å†…éƒ¨ä¸Šæ–¹
            if label_y + baseline > height:
                label_y = y1 + text_height + baseline + 10
            
            # ç¡®ä¿æ ‡ç­¾èƒŒæ™¯æ¡†ä¸è¶…å‡ºå·¦å³è¾¹ç•Œ
            if label_x + text_width > width:
                label_x = width - text_width - 5
            
            if label_x < 0:
                label_x = 5
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯æ¡†
            cv2.rectangle(vis_image, 
                         (label_x - 5, label_y - text_height - baseline - 5),
                         (label_x + text_width + 5, label_y + baseline + 5),
                         (0, 255, 0), -1)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            cv2.putText(vis_image, label, (label_x, label_y), 
                       font, font_scale, (0, 0, 0), thickness)
        
        return vis_image

class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, input_path: str, output_path: str, detector: YOLODetectionClassifier, 
                 visualize: bool = False, max_workers: int = 4, batch_size: int = 8, save_labels: bool = False):
        """
        åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨
        
        Args:
            input_path: è¾“å…¥è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            detector: YOLOæ£€æµ‹å™¨
            visualize: æ˜¯å¦å¯è§†åŒ–
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
            batch_size: å›¾åƒæ‰¹å¤„ç†å¤§å°
            save_labels: æ˜¯å¦ä¿å­˜YOLOæ ¼å¼æ ‡ç­¾
        """
        self.input_path = Path(input_path)
        self.output_path = Path(output_path)
        self.detector = detector
        self.visualize = visualize
        self.max_workers = max_workers
        self.batch_size = batch_size
        self.save_labels = save_labels
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯å’Œçº¿ç¨‹é”
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'classified_files': {},
            'unknown_files': 0,
            'error_files': 0,
            'total_inference_time': 0.0,  # ç´¯è®¡æ¨ç†æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡ï¼‰
            'total_inferences': 0,        # æ€»æ¨ç†æ¬¡æ•°
        }
        self.stats_lock = threading.Lock()
        
        # è¿›åº¦æ˜¾ç¤º
        self.progress_count = 0
        self.start_time = None
        self.end_time = None
        
        # æ¨ç†é˜¶æ®µæ—¶é—´ç»Ÿè®¡
        self.inference_start_time = None  # ç¬¬ä¸€æ¬¡æ¨ç†å¼€å§‹æ—¶é—´
        self.inference_end_time = None    # æœ€åä¸€æ¬¡æ¨ç†ç»“æŸæ—¶é—´
    
    def get_relative_path(self, file_path: Path) -> Path:
        """è·å–ç›¸å¯¹äºè¾“å…¥è·¯å¾„çš„ç›¸å¯¹è·¯å¾„"""
        try:
            return file_path.relative_to(self.input_path)
        except ValueError:
            return file_path.name
    
    def record_inference_start(self):
        """è®°å½•æ¨ç†é˜¶æ®µå¼€å§‹æ—¶é—´ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.stats_lock:
            if self.inference_start_time is None:
                self.inference_start_time = time.time()
    
    def record_inference_end(self):
        """è®°å½•æ¨ç†é˜¶æ®µç»“æŸæ—¶é—´ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.stats_lock:
            self.inference_end_time = time.time()
    
    def update_stats_thread_safe(self, detected_classes: List[str], is_frame: bool = False, inference_time: float = 0.0):
        """çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats_lock:
            self.progress_count += 1
            
            # è®°å½•æ¨ç†æ—¶é—´å’Œæ¬¡æ•°
            if inference_time > 0:
                self.stats['total_inference_time'] += inference_time
                self.stats['total_inferences'] += 1
            
            if not detected_classes:
                if is_frame:
                    if 'frame_unknown_files' not in self.stats:
                        self.stats['frame_unknown_files'] = 0
                    self.stats['frame_unknown_files'] += 1
                else:
                    self.stats['unknown_files'] += 1
            else:
                # åªç»Ÿè®¡ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç±»åˆ«ä»¥é¿å…é‡å¤è®¡æ•°
                category = detected_classes[0]
                if is_frame:
                    if 'frame_classified_files' not in self.stats:
                        self.stats['frame_classified_files'] = {}
                    if category not in self.stats['frame_classified_files']:
                        self.stats['frame_classified_files'][category] = 0
                    self.stats['frame_classified_files'][category] += 1
                else:
                    if category not in self.stats['classified_files']:
                        self.stats['classified_files'][category] = 0
                    self.stats['classified_files'][category] += 1
    
    def update_processed_files(self):
        """æ›´æ–°å·²å¤„ç†æ–‡ä»¶æ•°"""
        with self.stats_lock:
            self.stats['processed_files'] += 1
    
    def update_error_files(self):
        """æ›´æ–°é”™è¯¯æ–‡ä»¶æ•°"""
        with self.stats_lock:
            self.stats['error_files'] += 1
    
    def show_progress(self, file_path: str = None):
        """æ˜¾ç¤ºå¤„ç†è¿›åº¦"""
        if self.start_time is None:
            return
            
        elapsed_time = time.time() - self.start_time
        with self.stats_lock:
            progress = self.progress_count
            total = self.stats['total_files']
            
        if total > 0:
            percentage = (progress / total) * 100
            avg_time = elapsed_time / progress if progress > 0 else 0
            eta = avg_time * (total - progress) if progress > 0 else 0
            
            if file_path:
                logger.info(f"è¿›åº¦: {progress}/{total} ({percentage:.1f}%) | "
                           f"å¹³å‡: {avg_time:.2f}s/æ–‡ä»¶ | "
                           f"é¢„è®¡å‰©ä½™: {eta:.0f}s | "
                           f"å½“å‰: {Path(file_path).name}")
            else:
                logger.info(f"è¿›åº¦: {progress}/{total} ({percentage:.1f}%) | "
                           f"å·²ç”¨æ—¶: {elapsed_time:.0f}s")
    
    def create_output_dirs(self, detected_classes: List[str], relative_path: Path) -> List[Path]:
        """
        åˆ›å»ºè¾“å‡ºç›®å½•
        
        Args:
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«
            relative_path: ç›¸å¯¹è·¯å¾„
            
        Returns:
            output_dirs: è¾“å‡ºç›®å½•åˆ—è¡¨
        """
        output_dirs = []
        
        if not detected_classes:
            # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œä¿å­˜åˆ°unknownæ–‡ä»¶å¤¹
            unknown_dir = self.output_path / "unknown" / relative_path.parent
            unknown_dir.mkdir(parents=True, exist_ok=True)
            output_dirs.append(unknown_dir)
        else:
            # ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„ç±»åˆ«åˆ›å»ºç›®å½•
            for class_name in detected_classes:
                class_dir = self.output_path / class_name / relative_path.parent
                class_dir.mkdir(parents=True, exist_ok=True)
                output_dirs.append(class_dir)
        
        return output_dirs
    
    def create_video_frame_dirs(self, detected_classes: List[str], video_name: str, relative_path: Path) -> List[Path]:
        """
        ä¸ºè§†é¢‘å¸§åˆ›å»ºè¾“å‡ºç›®å½•
        
        Args:
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«
            video_name: è§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            relative_path: ç›¸å¯¹è·¯å¾„
            
        Returns:
            output_dirs: è¾“å‡ºç›®å½•åˆ—è¡¨
        """
        output_dirs = []
        
        if not detected_classes:
            # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œä¿å­˜åˆ°unknownæ–‡ä»¶å¤¹ä¸‹çš„è§†é¢‘åæ–‡ä»¶å¤¹
            unknown_dir = self.output_path / "unknown" / relative_path.parent / video_name
            unknown_dir.mkdir(parents=True, exist_ok=True)
            output_dirs.append(unknown_dir)
        else:
            # ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„ç±»åˆ«åˆ›å»ºç›®å½•
            for class_name in detected_classes:
                class_dir = self.output_path / class_name / relative_path.parent / video_name
                class_dir.mkdir(parents=True, exist_ok=True)
                output_dirs.append(class_dir)
        
        return output_dirs
    
    def save_file_to_dirs(self, source_path: Path, output_dirs: List[Path], 
                         detected_classes: List[str]):
        """
        å°†æ–‡ä»¶ä¿å­˜åˆ°å¤šä¸ªç›®å½•
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„
            output_dirs: è¾“å‡ºç›®å½•åˆ—è¡¨
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«
        """
        filename = source_path.name
        
        for i, output_dir in enumerate(output_dirs):
            dest_path = output_dir / filename
            
            try:
                # å¤åˆ¶åŸæ–‡ä»¶
                shutil.copy2(source_path, dest_path)
                
                category = "unknown" if not detected_classes else (
                    detected_classes[i] if i < len(detected_classes) else detected_classes[0]
                )
                
            except Exception as e:
                logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {dest_path}: {e}")
                self.update_error_files()
    
    def save_visualization(self, image: np.ndarray, results_info: dict, output_dirs: List[Path], 
                          filename: str, detected_classes: List[str]):
        """ä¿å­˜å¯è§†åŒ–ç»“æœåˆ°visç›®å½•ï¼Œæ¯ä¸ªæ ‡ç­¾ç›®å½•ä¸‹åªæ˜¾ç¤ºè¯¥æ ‡ç­¾çš„æ£€æµ‹æ¡†"""
        if not self.visualize:
            return
        
        # ä¸ºæ¯ä¸ªè¾“å‡ºç›®å½•åˆ›å»ºå¯¹åº”çš„visç›®å½•
        for i, output_dir in enumerate(output_dirs):
            # è·å–ç›¸å¯¹äºè¾“å‡ºæ ¹ç›®å½•çš„è·¯å¾„
            try:
                relative_to_output = output_dir.relative_to(self.output_path)
                vis_dir = self.output_path / "vis" / relative_to_output
                vis_dir.mkdir(parents=True, exist_ok=True)
                
                # ç¡®å®šå½“å‰ç›®å½•å¯¹åº”çš„æ ‡ç­¾ç±»åˆ«
                if not detected_classes:
                    # å¦‚æœæ˜¯unknownç›®å½•ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹æ¡†
                    target_class = None
                else:
                    # æ ¹æ®ç›®å½•åç¡®å®šç›®æ ‡ç±»åˆ«
                    # ä»ç›®å½•è·¯å¾„ä¸­æå–ç±»åˆ«åï¼ˆæœ€åä¸€ä¸ªç›®å½•åï¼‰
                    target_class = detected_classes[i] if i < len(detected_classes) else detected_classes[0]
                
                # ç”ŸæˆåªåŒ…å«ç›®æ ‡ç±»åˆ«æ£€æµ‹æ¡†çš„å¯è§†åŒ–å›¾ç‰‡
                vis_image = self.detector.visualize_detection(image, results_info, target_class)
                
                vis_path = vis_dir / filename
                cv2.imwrite(str(vis_path), vis_image)
                logger.info(f"å·²ä¿å­˜å¯è§†åŒ–ç»“æœ: {vis_path} (ç±»åˆ«: {target_class if target_class else 'unknown'})")
            except Exception as e:
                logger.error(f"ä¿å­˜å¯è§†åŒ–ç»“æœå¤±è´¥: {e}")
    
    def save_frame_to_dirs(self, frame: np.ndarray, output_dirs: List[Path], 
                          frame_filename: str, detected_classes: List[str]):
        """
        å°†è§†é¢‘å¸§ä¿å­˜åˆ°å¤šä¸ªç›®å½•
        
        Args:
            frame: è§†é¢‘å¸§
            output_dirs: è¾“å‡ºç›®å½•åˆ—è¡¨
            frame_filename: å¸§æ–‡ä»¶å
            detected_classes: æ£€æµ‹åˆ°çš„ç±»åˆ«
        """
        for i, output_dir in enumerate(output_dirs):
            frame_path = output_dir / frame_filename
            
            try:
                # ä¿å­˜å¸§å›¾ç‰‡
                cv2.imwrite(str(frame_path), frame)
                
            except Exception as e:
                logger.error(f"ä¿å­˜å¸§å¤±è´¥ {frame_path}: {e}")
                self.update_error_files()
    
    def save_yolo_label(self, image_path: Path, detections: list, image_shape: tuple, image_data: np.ndarray = None, video_name: str = None, label_filename: str = None):
        """
        ä¿å­˜YOLOæ ¼å¼æ ‡ç­¾æ–‡ä»¶å’Œå¯¹åº”çš„å›¾ç‰‡åˆ°yolo_datasetç›®å½•
        Args:
            image_path: åŸå›¾åƒè·¯å¾„ï¼ˆPathå¯¹è±¡ï¼‰
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºdictï¼ŒåŒ…å«class/confidence/bbox
            image_shape: (height, width)
            image_data: å›¾åƒæ•°æ®ï¼ˆnumpyæ•°ç»„ï¼‰
            video_name: è§†é¢‘æ–‡ä»¶åï¼ˆå¦‚æœ‰ï¼Œè¡¨ç¤ºä¸ºè§†é¢‘å¸§æ ‡ç­¾ï¼‰
            label_filename: æŒ‡å®šæ ‡ç­¾æ–‡ä»¶åï¼ˆå¦‚æœ‰ï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
        """
        if not detections:
            return
        
        # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œæ„é€ æ ‡ç­¾å’Œå›¾ç‰‡æ–‡ä»¶è·¯å¾„
        relative_path = self.get_relative_path(image_path)
        
        # åˆ›å»ºyolo_datasetç›®å½•ç»“æ„
        if video_name:
            # è§†é¢‘å¸§çš„æƒ…å†µ
            yolo_images_dir = self.output_path / "yolo_dataset" / "images" / relative_path.parent / video_name
            yolo_labels_dir = self.output_path / "yolo_dataset" / "labels" / relative_path.parent / video_name
        else:
            # å›¾ç‰‡çš„æƒ…å†µ
            yolo_images_dir = self.output_path / "yolo_dataset" / "images" / relative_path.parent
            yolo_labels_dir = self.output_path / "yolo_dataset" / "labels" / relative_path.parent
        
        # åˆ›å»ºç›®å½•
        yolo_images_dir.mkdir(parents=True, exist_ok=True)
        yolo_labels_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¡®å®šæ–‡ä»¶å
        if label_filename:
            # è§†é¢‘å¸§çš„æƒ…å†µï¼Œä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶å
            base_name = label_filename.replace('.txt', '')
            image_filename = base_name + '.jpg'
            label_filename_final = label_filename
        else:
            # å›¾ç‰‡çš„æƒ…å†µï¼Œä½¿ç”¨åŸæ–‡ä»¶å
            base_name = image_path.stem
            image_filename = image_path.name
            label_filename_final = base_name + '.txt'
        
        # ä¿å­˜å›¾ç‰‡
        if image_data is not None:
            image_path_yolo = yolo_images_dir / image_filename
            try:
                cv2.imwrite(str(image_path_yolo), image_data)
                logger.info(f"å·²ä¿å­˜YOLOå›¾ç‰‡: {image_path_yolo}")
            except Exception as e:
                logger.error(f"ä¿å­˜YOLOå›¾ç‰‡å¤±è´¥: {e}")
        else:
            # å¦‚æœæ²¡æœ‰æä¾›å›¾åƒæ•°æ®ï¼Œå¤åˆ¶åŸæ–‡ä»¶
            image_path_yolo = yolo_images_dir / image_filename
            try:
                shutil.copy2(image_path, image_path_yolo)
                logger.info(f"å·²å¤åˆ¶YOLOå›¾ç‰‡: {image_path_yolo}")
            except Exception as e:
                logger.error(f"å¤åˆ¶YOLOå›¾ç‰‡å¤±è´¥: {e}")
        
        # ä¿å­˜æ ‡ç­¾æ–‡ä»¶
        label_path = yolo_labels_dir / label_filename_final
        h, w = image_shape[:2]
        lines = []
        for det in detections:
            class_name = det['class']
            if class_name in self.detector.classes:
                class_id = self.detector.classes.index(class_name)
            else:
                continue
            x1, y1, x2, y2 = det['bbox']
            # å½’ä¸€åŒ–
            x_center = ((x1 + x2) / 2) / w
            y_center = ((y1 + y2) / 2) / h
            width = (x2 - x1) / w
            height = (y2 - y1) / h
            lines.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
        
        # å†™å…¥æ ‡ç­¾æ–‡ä»¶
        try:
            with open(label_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines) + '\n')
            logger.info(f"å·²ä¿å­˜YOLOæ ‡ç­¾: {label_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜YOLOæ ‡ç­¾å¤±è´¥: {e}")
    
    def process_images_batch(self, image_paths: List[Path]) -> None:
        """
        æ‰¹é‡å¤„ç†å›¾åƒæ–‡ä»¶
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
        """
        try:
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²è·¯å¾„
            str_paths = [str(path) for path in image_paths]
            
            # æ‰¹é‡æ£€æµ‹
            batch_results = self.detector.detect_images_batch(str_paths, self.batch_size, self)
            
            # å¤„ç†æ¯ä¸ªç»“æœ
            for image_path_str, detected_classes, image, results_info, inference_time in batch_results:
                image_path = Path(image_path_str)
                
                try:
                    if image is None:
                        logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                        self.update_error_files()
                        continue
                    
                    # è·å–ç›¸å¯¹è·¯å¾„
                    relative_path = self.get_relative_path(image_path)
                    
                    # åˆ›å»ºè¾“å‡ºç›®å½•
                    output_dirs = self.create_output_dirs(detected_classes, relative_path)
                    
                    # ä¿å­˜æ–‡ä»¶
                    self.save_file_to_dirs(image_path, output_dirs, detected_classes)
                    
                    # å¯è§†åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.visualize and results_info['detections']:
                        self.save_visualization(image, results_info, output_dirs, image_path.name, detected_classes)
                    
                    # ä¿å­˜YOLOæ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.save_labels and results_info['detections']:
                        self.save_yolo_label(image_path, results_info['detections'], image.shape, image_data=image)
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self.update_stats_thread_safe(detected_classes, is_frame=False, inference_time=inference_time)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å›¾åƒæ—¶å‘ç”Ÿé”™è¯¯ {image_path}: {e}")
                    self.update_error_files()
            
            # æ›´æ–°å·²å¤„ç†æ–‡ä»¶æ•°
            self.update_processed_files()
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å›¾åƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # å›é€€åˆ°å•å¼ å¤„ç†
            for image_path in image_paths:
                self.process_image(image_path)
    
    def process_video_worker(self, video_path: Path) -> None:
        """
        å·¥ä½œçº¿ç¨‹å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            self.process_video(video_path)
            self.update_processed_files()
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯ {video_path}: {e}")
            self.update_error_files()
    
    def process_image(self, image_path: Path):
        """å¤„ç†å•å¼ å›¾åƒï¼ˆç”¨äºå›é€€å¤„ç†ï¼‰"""
        try:
            # æ£€æµ‹å›¾åƒ
            detected_classes, image, results_info, inference_time = self.detector.detect_image(str(image_path), self)
            
            if image is None:
                logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                self.update_error_files()
                return
            
            # è·å–ç›¸å¯¹è·¯å¾„
            relative_path = self.get_relative_path(image_path)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dirs = self.create_output_dirs(detected_classes, relative_path)
            
            # ä¿å­˜æ–‡ä»¶
            self.save_file_to_dirs(image_path, output_dirs, detected_classes)
            
            # å¯è§†åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.visualize and results_info['detections']:
                self.save_visualization(image, results_info, output_dirs, image_path.name, detected_classes)
            
            # ä¿å­˜YOLOæ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.save_labels and results_info['detections']:
                self.save_yolo_label(image_path, results_info['detections'], image.shape, image_data=image)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.update_stats_thread_safe(detected_classes, is_frame=False, inference_time=inference_time)
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾åƒæ—¶å‘ç”Ÿé”™è¯¯ {image_path}: {e}")
            self.update_error_files()
    
    def process_video(self, video_path: Path):
        """å¤„ç†è§†é¢‘æ–‡ä»¶ - é€å¸§æ¨ç†å¹¶è¾“å‡ºå›¾ç‰‡"""
        logger.info(f"æ­£åœ¨å¤„ç†è§†é¢‘: {video_path}")
        
        try:
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
                self.update_error_files()
                return
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            logger.info(f"è§†é¢‘æ€»å¸§æ•°: {total_frames}, FPS: {fps}")
            
            # è·å–ç›¸å¯¹è·¯å¾„å’Œè§†é¢‘åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
            relative_path = self.get_relative_path(video_path)
            video_name = video_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
            
            frame_idx = 0
            processed_frames = 0
            
            # é€å¸§å¤„ç†
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ£€æµ‹å½“å‰å¸§
                detected_classes, results_info, inference_time = self.detector.detect_video_frame(frame, self)
                
                # åˆ›å»ºå¸§æ–‡ä»¶åï¼ˆ6ä½æ•°å­—ï¼Œå·¦ä¾§è¡¥é›¶ï¼‰
                frame_filename = f"frame_{frame_idx:06d}.jpg"
                label_filename = f"frame_{frame_idx:06d}.txt"
                
                # ä¸ºæ¯ä¸€å¸§åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŸºäºæ£€æµ‹ç»“æœï¼‰
                output_dirs = self.create_video_frame_dirs(detected_classes, video_name, relative_path)
                
                # ä¿å­˜å½“å‰å¸§
                self.save_frame_to_dirs(frame, output_dirs, frame_filename, detected_classes)
                
                # æ›´æ–°å¸§ç»Ÿè®¡ä¿¡æ¯
                self.update_stats_thread_safe(detected_classes, is_frame=True, inference_time=inference_time)
                
                # å¯è§†åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.visualize and results_info['detections']:
                    # ä¸ºæ¯ä¸ªè¾“å‡ºç›®å½•åˆ›å»ºå¯¹åº”çš„visç›®å½•å¹¶ä¿å­˜å¯¹åº”çš„å¯è§†åŒ–ç»“æœ
                    for i, output_dir in enumerate(output_dirs):
                        try:
                            relative_to_output = output_dir.relative_to(self.output_path)
                            vis_dir = self.output_path / "vis" / relative_to_output
                            vis_dir.mkdir(parents=True, exist_ok=True)
                            
                            # ç¡®å®šå½“å‰ç›®å½•å¯¹åº”çš„æ ‡ç­¾ç±»åˆ«
                            if not detected_classes:
                                # å¦‚æœæ˜¯unknownç›®å½•ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹æ¡†
                                target_class = None
                            else:
                                # æ ¹æ®ç›®å½•åç¡®å®šç›®æ ‡ç±»åˆ«
                                target_class = detected_classes[i] if i < len(detected_classes) else detected_classes[0]
                            
                            # ç”ŸæˆåªåŒ…å«ç›®æ ‡ç±»åˆ«æ£€æµ‹æ¡†çš„å¯è§†åŒ–å›¾ç‰‡
                            vis_image = self.detector.visualize_detection(frame, results_info, target_class)
                            
                            vis_path = vis_dir / frame_filename
                            cv2.imwrite(str(vis_path), vis_image)
                        except Exception as e:
                            logger.error(f"ä¿å­˜å¯è§†åŒ–å¸§å¤±è´¥: {e}")
                
                # ä¿å­˜YOLOæ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.save_labels and results_info['detections']:
                    self.save_yolo_label(video_path, results_info['detections'], frame.shape, image_data=frame, video_name=video_name, label_filename=label_filename)
                
                frame_idx += 1
                processed_frames += 1
                
                # æ¯å¤„ç†100å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
                if frame_idx % 100 == 0:
                    progress = (frame_idx / total_frames) * 100
                    logger.info(f"è§†é¢‘ {video_path.name} è¿›åº¦: {frame_idx}/{total_frames} ({progress:.1f}%)")
            
            cap.release()
            
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {video_path.name}ï¼Œå…±å¤„ç† {processed_frames} å¸§")
            
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯ {video_path}: {e}")
            self.update_error_files()
    
    def process_all_files(self):
        """æ™ºèƒ½å¤„ç†æ‰€æœ‰æ–‡ä»¶ - æ ¹æ®æ–‡ä»¶ç±»å‹å’Œæ•°é‡ä¼˜åŒ–ç­–ç•¥"""
        logger.info(f"å¼€å§‹å¤„ç†ç›®å½•: {self.input_path}")
        
        # æ”¶é›†æ‰€æœ‰è¦å¤„ç†çš„æ–‡ä»¶
        all_files = []
        
        if self.input_path.is_file():
            all_files.append(self.input_path)
        else:
            for file_path in self.input_path.rglob('*'):
                if file_path.is_file():
                    ext = file_path.suffix.lower()
                    if ext in self.image_extensions or ext in self.video_extensions:
                        all_files.append(file_path)
        
        # åˆ†ç¦»å›¾åƒå’Œè§†é¢‘æ–‡ä»¶
        image_files = []
        video_files = []
        
        for file_path in all_files:
            ext = file_path.suffix.lower()
            if ext in self.image_extensions:
                image_files.append(file_path)
            elif ext in self.video_extensions:
                video_files.append(file_path)
        
        self.stats['total_files'] = len(all_files)
        logger.info(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†:")
        logger.info(f"  å›¾åƒæ–‡ä»¶: {len(image_files)} ä¸ª")
        logger.info(f"  è§†é¢‘æ–‡ä»¶: {len(video_files)} ä¸ª")
        
        # ğŸš€ æ™ºèƒ½ç­–ç•¥é€‰æ‹©
        optimal_strategy = self._choose_optimal_strategy(image_files, video_files)
        logger.info(f"  é‡‡ç”¨ç­–ç•¥: {optimal_strategy['name']}")
        logger.info(f"  å¹¶è¡Œåº¦: {optimal_strategy['workers']} çº¿ç¨‹")
        logger.info(f"  æ‰¹å¤„ç†å¤§å°: {optimal_strategy['batch_size']}")
        
        if not all_files:
            logger.warning("æœªæ‰¾åˆ°è¦å¤„ç†çš„æ–‡ä»¶")
            return
        
        self.start_time = time.time()
        
        # æ ¹æ®é€‰æ‹©çš„ç­–ç•¥æ‰§è¡Œå¤„ç†
        if optimal_strategy['strategy'] == 'batch_only':
            self._process_batch_only(image_files, video_files, optimal_strategy)
        else:
            self._process_with_threads(image_files, video_files, optimal_strategy)
        
        # æ˜¾ç¤ºæœ€ç»ˆè¿›åº¦
        self.show_progress()
        
        # è®¾ç½®ç»“æŸæ—¶é—´
        self.end_time = time.time()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self.print_stats()
    
    def _choose_optimal_strategy(self, image_files, video_files):
        """æ ¹æ®æ–‡ä»¶æ•°é‡å’Œç±»å‹é€‰æ‹©æœ€ä¼˜å¤„ç†ç­–ç•¥"""
        total_images = len(image_files)
        total_videos = len(video_files)
        
        # ç­–ç•¥1: çº¯æ‰¹é‡å¤„ç†ï¼ˆé€‚åˆå¤§é‡å›¾åƒï¼Œå°‘é‡æˆ–æ— è§†é¢‘ï¼‰
        if total_images >= 100 and total_videos <= 2:
            return {
                'strategy': 'batch_only',
                'name': 'æ‰¹é‡ä¼˜åŒ–æ¨¡å¼ï¼ˆæ¨èï¼‰',
                'workers': 1,  # ä½¿ç”¨å•çº¿ç¨‹é¿å…GPUç«äº‰
                'batch_size': min(32, max(8, total_images // 10))  # åŠ¨æ€æ‰¹å¤§å°
            }
        
        # ç­–ç•¥2: å°è§„æ¨¡å¤„ç†ï¼ˆæ–‡ä»¶æ•°é‡å°‘ï¼‰
        elif total_images + total_videos <= 50:
            return {
                'strategy': 'single_thread',
                'name': 'å•çº¿ç¨‹æ¨¡å¼ï¼ˆå°è§„æ¨¡ï¼‰',
                'workers': 1,
                'batch_size': min(8, total_images)
            }
        
        # ç­–ç•¥3: æ··åˆå¹¶è¡Œå¤„ç†ï¼ˆå›¾åƒå’Œè§†é¢‘éƒ½è¾ƒå¤šï¼‰
        else:
            # åŠ¨æ€è°ƒæ•´çº¿ç¨‹æ•°ï¼Œé¿å…è¿‡åº¦å¹¶è¡Œ
            optimal_workers = min(self.max_workers, 
                                max(1, min(4, total_videos + (total_images // 50))))
            return {
                'strategy': 'hybrid_parallel',
                'name': 'æ··åˆå¹¶è¡Œæ¨¡å¼',
                'workers': optimal_workers,
                'batch_size': min(16, max(4, total_images // optimal_workers))
            }
    
    def _process_batch_only(self, image_files, video_files, strategy):
        """æ‰¹é‡ä¼˜åŒ–å¤„ç†æ¨¡å¼"""
        logger.info("ğŸš€ ä½¿ç”¨æ‰¹é‡ä¼˜åŒ–æ¨¡å¼å¤„ç†")
        
        # å¤„ç†å›¾åƒæ–‡ä»¶ - ä½¿ç”¨å¤§æ‰¹é‡
        if image_files:
            batch_size = strategy['batch_size']
            total_batches = (len(image_files) + batch_size - 1) // batch_size
            
            for i in range(0, len(image_files), batch_size):
                batch = image_files[i:i + batch_size]
                batch_num = i // batch_size + 1
                logger.info(f"å¤„ç†å›¾åƒæ‰¹æ¬¡ {batch_num}/{total_batches}: {len(batch)} ä¸ªæ–‡ä»¶")
                
                self.process_images_batch(batch)
                
                # æ˜¾ç¤ºæ‰¹æ¬¡è¿›åº¦
                if batch_num % 5 == 0 or batch_num == total_batches:
                    progress = (batch_num / total_batches) * 100
                    logger.info(f"å›¾åƒå¤„ç†è¿›åº¦: {progress:.1f}%")
        
        # å¤„ç†è§†é¢‘æ–‡ä»¶ - ä¸²è¡Œå¤„ç†é¿å…ç«äº‰
        for i, video_file in enumerate(video_files):
            logger.info(f"å¤„ç†è§†é¢‘ {i+1}/{len(video_files)}: {video_file.name}")
            self.process_video_worker(video_file)
    
    def _process_with_threads(self, image_files, video_files, strategy):
        """å¤šçº¿ç¨‹å¤„ç†æ¨¡å¼"""
        logger.info(f"ğŸ”„ ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼å¤„ç† ({strategy['workers']} çº¿ç¨‹)")
        
        # åˆ›å»ºçº¿ç¨‹æ± å¤„ç†
        with ThreadPoolExecutor(max_workers=strategy['workers']) as executor:
            futures = []
            
            # æäº¤å›¾åƒæ‰¹å¤„ç†ä»»åŠ¡
            if image_files:
                batch_size = strategy['batch_size']
                # å°†å›¾åƒæ–‡ä»¶åˆ†æ‰¹
                for i in range(0, len(image_files), batch_size):
                    batch = image_files[i:i + batch_size]
                    future = executor.submit(self.process_images_batch, batch)
                    futures.append(future)
                    logger.info(f"æäº¤å›¾åƒæ‰¹å¤„ç†ä»»åŠ¡: {len(batch)} ä¸ªæ–‡ä»¶")
            
            # æäº¤è§†é¢‘å¤„ç†ä»»åŠ¡
            for video_file in video_files:
                future = executor.submit(self.process_video_worker, video_file)
                futures.append(future)
                logger.info(f"æäº¤è§†é¢‘å¤„ç†ä»»åŠ¡: {video_file.name}")
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ˜¾ç¤ºè¿›åº¦
            completed_tasks = 0
            total_tasks = len(futures)
            
            for future in as_completed(futures):
                try:
                    future.result()  # è·å–ç»“æœä»¥æ•è·å¼‚å¸¸
                    completed_tasks += 1
                    
                    # æ˜¾ç¤ºä»»åŠ¡å®Œæˆè¿›åº¦
                    task_progress = (completed_tasks / total_tasks) * 100
                    logger.info(f"ä»»åŠ¡è¿›åº¦: {completed_tasks}/{total_tasks} ({task_progress:.1f}%)")
                    
                except Exception as e:
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                    completed_tasks += 1
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 50)
        logger.info("å¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        logger.info(f"å·²å¤„ç†: {self.stats['processed_files']}")
        logger.info(f"é”™è¯¯æ–‡ä»¶: {self.stats['error_files']}")
        logger.info(f"æœªæ£€æµ‹åˆ°ç›®æ ‡çš„æ–‡ä»¶: {self.stats['unknown_files']}")
        
        logger.info("å„ç±»åˆ«æ–‡ä»¶æ•°:")
        for category, count in self.stats['classified_files'].items():
            logger.info(f"  {category}: {count}")
        
        # è¾“å‡ºè§†é¢‘å¸§ç»Ÿè®¡ä¿¡æ¯
        if 'frame_classified_files' in self.stats or 'frame_unknown_files' in self.stats:
            logger.info("\nè§†é¢‘å¸§ç»Ÿè®¡:")
            if 'frame_unknown_files' in self.stats:
                logger.info(f"æœªæ£€æµ‹åˆ°ç›®æ ‡çš„å¸§: {self.stats['frame_unknown_files']}")
            
            if 'frame_classified_files' in self.stats:
                logger.info("å„ç±»åˆ«å¸§æ•°:")
                for category, count in self.stats['frame_classified_files'].items():
                    logger.info(f"  {category}: {count}")
        
        # è¾“å‡ºæ€»å¤„ç†æ—¶é—´å’Œæ¨ç†æ—¶é—´
        if self.start_time and self.end_time:
            total_processing_time = self.end_time - self.start_time
            logger.info(f"\næ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’")
            
            # æ¨ç†é˜¶æ®µæ€»æ—¶é•¿ï¼ˆçœŸå®çš„æ¨ç†æ—¶é—´æ®µï¼‰
            if self.inference_start_time and self.inference_end_time:
                inference_phase_duration = self.inference_end_time - self.inference_start_time
                logger.info(f"æ¨ç†é˜¶æ®µæ€»æ—¶é•¿: {inference_phase_duration:.3f} ç§’")
                logger.info(f"æ¨ç†æ—¶é—´å æ¯”: {inference_phase_duration / total_processing_time * 100:.1f}%")
            else:
                logger.info("æ¨ç†é˜¶æ®µæ€»æ—¶é•¿: æ— æ³•è®¡ç®—ï¼ˆæ— æ¨ç†æ“ä½œï¼‰")
            
            # ç´¯è®¡æ¨ç†æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡æ¨ç†æ—¶é—´ï¼‰
            logger.info(f"ç´¯è®¡æ¨ç†æ—¶é—´: {self.stats['total_inference_time']:.3f} ç§’")
            
            # è®¡ç®—å¤„ç†çš„æ€»é¡¹ç›®æ•°ï¼ˆæ–‡ä»¶ + å¸§ï¼‰
            total_processed_items = self.stats['processed_files']
            if 'frame_classified_files' in self.stats:
                total_processed_items += sum(self.stats['frame_classified_files'].values())
            if 'frame_unknown_files' in self.stats:
                total_processed_items += self.stats['frame_unknown_files']
            
            if self.stats['processed_files'] > 0:
                logger.info(f"å¹³å‡æ¯æ–‡ä»¶å¤„ç†æ—¶é—´: {total_processing_time / self.stats['processed_files']:.3f} ç§’")
            
            if self.stats['total_inferences'] > 0:
                logger.info(f"æ€»æ¨ç†æ¬¡æ•°: {self.stats['total_inferences']}")
                logger.info(f"å¹³å‡å•æ¬¡æ¨ç†æ—¶é—´: {self.stats['total_inference_time'] / self.stats['total_inferences'] * 1000:.1f} æ¯«ç§’")
                
                # ä½¿ç”¨æ¨ç†é˜¶æ®µæ€»æ—¶é•¿è®¡ç®—å®é™…FPS
                if self.inference_start_time and self.inference_end_time:
                    inference_phase_duration = self.inference_end_time - self.inference_start_time
                    if inference_phase_duration > 0:
                        logger.info(f"å®é™…æ¨ç†é€Ÿåº¦: {self.stats['total_inferences'] / inference_phase_duration:.1f} FPS")
                else:
                    logger.info("å®é™…æ¨ç†é€Ÿåº¦: æ— æ³•è®¡ç®—")
        else:
            logger.info("\næ—¶é—´ç»Ÿè®¡ä¿¡æ¯: æ— æ³•è·å–ï¼ˆè®¡æ—¶é”™è¯¯ï¼‰")

        logger.info("=" * 50)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»è„šæœ¬ï¼ˆæ”¯æŒå¹¶è¡Œå¤„ç†ï¼‰')
    
    parser.add_argument('--input', '-i', required=True, 
                       help='è¾“å…¥è·¯å¾„ï¼ˆå›¾åƒ/è§†é¢‘æ–‡ä»¶æˆ–åŒ…å«å›¾åƒ/è§†é¢‘çš„ç›®å½•ï¼‰')
    parser.add_argument('--output', '-o', required=True, 
                       help='è¾“å‡ºè·¯å¾„ï¼ˆåˆ†ç±»ç»“æœä¿å­˜ç›®å½•ï¼‰')
    parser.add_argument('--model', '-m', required=True, 
                       help='YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.ptæ–‡ä»¶ï¼‰')
    parser.add_argument('--classes', '-c', required=True, 
                       help='ç±»åˆ«æ–‡ä»¶è·¯å¾„ï¼ˆclasses.txtï¼‰')
    parser.add_argument('--confidence', '-conf', type=float, default=0.5,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰')
    parser.add_argument('--visualize', '-v', action='store_true',
                       help='æ˜¯å¦ä¿å­˜å¯è§†åŒ–æ£€æµ‹ç»“æœ')
    parser.add_argument('--max-workers', '-w', type=int, default=4,
                       help='æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--batch-size', '-b', type=int, default=8,
                       help='å›¾åƒæ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 8ï¼‰')
    parser.add_argument('--debug', '-d', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¢«è¿‡æ»¤æ‰çš„ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœ')
    parser.add_argument('--save-labels', '-sl', action='store_true',
                       help='æ˜¯å¦ä¿å­˜YOLOæ ¼å¼æ ‡ç­¾')
    
    args = parser.parse_args()
    
    # æ ¹æ®debugå‚æ•°è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.info("å·²å¯ç”¨è°ƒè¯•æ¨¡å¼")
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not os.path.exists(args.input):
        logger.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        return
    
    if not os.path.exists(args.model):
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        return
    
    if not os.path.exists(args.classes):
        logger.error(f"ç±»åˆ«æ–‡ä»¶ä¸å­˜åœ¨: {args.classes}")
        return
    
    if args.max_workers < 1:
        logger.error("å¹¶è¡Œçº¿ç¨‹æ•°å¿…é¡»å¤§äº0")
        return
    
    if args.batch_size < 1:
        logger.error("æ‰¹å¤„ç†å¤§å°å¿…é¡»å¤§äº0")
        return
    
    try:
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        detector = YOLODetectionClassifier(
            model_path=args.model,
            classes_path=args.classes,
            confidence_threshold=args.confidence
        )
        
        # åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨
        processor = FileProcessor(
            input_path=args.input,
            output_path=args.output,
            detector=detector,
            visualize=args.visualize,
            max_workers=args.max_workers,
            batch_size=args.batch_size,
            save_labels=args.save_labels
        )
        
        # å¤„ç†æ‰€æœ‰æ–‡ä»¶
        processor.process_all_files()
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    main() 